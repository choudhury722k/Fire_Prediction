{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RGB.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ef1322-fba2-4e89-ef48-54b250dd9fb5"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd\n",
        "!pip install pandas numpy matplotlib\n",
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package xxd.\n",
            "(Reading database ... 148486 files and directories currently installed.)\n",
            "Preparing to unpack .../xxd_2%3a8.0.1453-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking xxd (2:8.0.1453-1ubuntu1.4) ...\n",
            "Setting up xxd (2:8.0.1453-1ubuntu1.4) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.39.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.6.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.34.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.5.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "dd32e7b6-c032-409c-a693-0a307926e499"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import fileinput\n",
        "\n",
        "print(f\"TensorFlow version = {tf.__version__}\\n\")\n",
        "\n",
        "# Set a fixed random seed value, for reproducibility, this will allow us to get\n",
        "# the same random numbers each time the notebook is run\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "CLASSES = [];\n",
        "\n",
        "for file in os.listdir(\"/content/\"):\n",
        "    if file.endswith(\".csv\"):\n",
        "        CLASSES.append(os.path.splitext(file)[0])\n",
        "\n",
        "CLASSES.sort()\n",
        "\n",
        "SAMPLES_WINDOW_LEN = 1\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "# create a one-hot encoded matrix that is used in the output\n",
        "ONE_HOT_ENCODED_CLASSES = np.eye(NUM_CLASSES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# read each csv file and push an input and output\n",
        "for class_index in range(NUM_CLASSES):\n",
        "  objectClass = CLASSES[class_index]\n",
        "  df = pd.read_csv(\"/content/\" + objectClass + \".csv\")\n",
        "  columns = list(df)\n",
        "  # get rid of pesky empty value lines of csv which cause NaN inputs to TensorFlow\n",
        "  df = df.dropna()\n",
        "  df = df.reset_index(drop=True)\n",
        "   \n",
        "  # calculate the number of objectClass recordings in the file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_WINDOW_LEN)\n",
        "  print(f\"\\u001b[32;4m{objectClass}\\u001b[0m class will be output \\u001b[32m{class_index}\\u001b[0m of the classifier\")\n",
        "  print(f\"{num_recordings} samples captured for training with inputs {list(df)} \\n\")\n",
        "\n",
        "  # graphing\n",
        "  plt.rcParams[\"figure.figsize\"] = (10,1)\n",
        "  pixels = np.array([df['Red'],df['Green'],df['Blue']],float)\n",
        "  pixels = np.transpose(pixels)\n",
        "  for i in range(num_recordings):\n",
        "    plt.axvline(x=i, linewidth=8, color=tuple(pixels[i]/np.max(pixels[i], axis=0)))\n",
        "  plt.show()\n",
        "  \n",
        "  #tensors\n",
        "  output = ONE_HOT_ENCODED_CLASSES[class_index]\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    row = []\n",
        "    for c in columns:\n",
        "      row.append(df[c][i])\n",
        "    tensor += row\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convert the list to numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Data set parsing and preparation complete.\")\n",
        "\n",
        "# Randomize the order of the inputs, so they can be evenly distributed for training, testing, and validation\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Swap the consecutive indexes (0, 1, 2, etc) with the randomized indexes\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Split the recordings (group of samples) into three sets: training, testing and validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Data set randomization and splitting complete.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version = 2.6.0\n",
            "\n",
            "\u001b[32;4mfire\u001b[0m class will be output \u001b[32m0\u001b[0m of the classifier\n",
            "158 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32;4mroom\u001b[0m class will be output \u001b[32m1\u001b[0m of the classifier\n",
            "306 samples captured for training with inputs ['Red', 'Green', 'Blue'] \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Data set parsing and preparation complete.\n",
            "Data set randomization and splitting complete.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a833b3-ed8d-4f46-8e6a-857e36421e16"
      },
      "source": [
        "# build the model and train it\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu')) # relu is used for performance\n",
        "model.add(tf.keras.layers.Dense(5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')) # softmax is used, because we only expect one class to occur per input\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=400, batch_size=4, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "70/70 [==============================] - 1s 4ms/step - loss: 0.2262 - mae: 0.4740 - val_loss: 0.2102 - val_mae: 0.4541\n",
            "Epoch 2/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.2007 - mae: 0.4395 - val_loss: 0.1849 - val_mae: 0.4179\n",
            "Epoch 3/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1783 - mae: 0.4071 - val_loss: 0.1621 - val_mae: 0.3833\n",
            "Epoch 4/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1580 - mae: 0.3763 - val_loss: 0.1392 - val_mae: 0.3529\n",
            "Epoch 5/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1351 - mae: 0.3444 - val_loss: 0.1153 - val_mae: 0.3176\n",
            "Epoch 6/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.1128 - mae: 0.3098 - val_loss: 0.0928 - val_mae: 0.2842\n",
            "Epoch 7/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0906 - mae: 0.2763 - val_loss: 0.0711 - val_mae: 0.2454\n",
            "Epoch 8/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0707 - mae: 0.2396 - val_loss: 0.0524 - val_mae: 0.2092\n",
            "Epoch 9/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0539 - mae: 0.2056 - val_loss: 0.0377 - val_mae: 0.1745\n",
            "Epoch 10/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0414 - mae: 0.1747 - val_loss: 0.0276 - val_mae: 0.1514\n",
            "Epoch 11/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0309 - mae: 0.1479 - val_loss: 0.0185 - val_mae: 0.1153\n",
            "Epoch 12/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0242 - mae: 0.1229 - val_loss: 0.0128 - val_mae: 0.0973\n",
            "Epoch 13/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0195 - mae: 0.1039 - val_loss: 0.0095 - val_mae: 0.0817\n",
            "Epoch 14/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0164 - mae: 0.0889 - val_loss: 0.0081 - val_mae: 0.0757\n",
            "Epoch 15/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0146 - mae: 0.0803 - val_loss: 0.0067 - val_mae: 0.0672\n",
            "Epoch 16/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0135 - mae: 0.0721 - val_loss: 0.0048 - val_mae: 0.0555\n",
            "Epoch 17/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0126 - mae: 0.0639 - val_loss: 0.0043 - val_mae: 0.0512\n",
            "Epoch 18/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0119 - mae: 0.0608 - val_loss: 0.0034 - val_mae: 0.0446\n",
            "Epoch 19/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0113 - mae: 0.0538 - val_loss: 0.0029 - val_mae: 0.0403\n",
            "Epoch 20/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0108 - mae: 0.0515 - val_loss: 0.0028 - val_mae: 0.0389\n",
            "Epoch 21/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0489 - val_loss: 0.0026 - val_mae: 0.0367\n",
            "Epoch 22/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0474 - val_loss: 0.0019 - val_mae: 0.0311\n",
            "Epoch 23/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0448 - val_loss: 0.0019 - val_mae: 0.0308\n",
            "Epoch 24/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0426 - val_loss: 0.0017 - val_mae: 0.0292\n",
            "Epoch 25/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0408 - val_loss: 0.0016 - val_mae: 0.0279\n",
            "Epoch 26/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0394 - val_loss: 0.0014 - val_mae: 0.0252\n",
            "Epoch 27/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0377 - val_loss: 0.0014 - val_mae: 0.0251\n",
            "Epoch 28/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0377 - val_loss: 0.0011 - val_mae: 0.0218\n",
            "Epoch 29/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0360 - val_loss: 0.0011 - val_mae: 0.0217\n",
            "Epoch 30/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0349 - val_loss: 0.0013 - val_mae: 0.0234\n",
            "Epoch 31/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0351 - val_loss: 9.2017e-04 - val_mae: 0.0198\n",
            "Epoch 32/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0340 - val_loss: 8.7127e-04 - val_mae: 0.0191\n",
            "Epoch 33/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0329 - val_loss: 7.9829e-04 - val_mae: 0.0181\n",
            "Epoch 34/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0320 - val_loss: 8.2889e-04 - val_mae: 0.0184\n",
            "Epoch 35/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0321 - val_loss: 7.4811e-04 - val_mae: 0.0173\n",
            "Epoch 36/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0308 - val_loss: 7.0933e-04 - val_mae: 0.0168\n",
            "Epoch 37/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0303 - val_loss: 6.6647e-04 - val_mae: 0.0161\n",
            "Epoch 38/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0291 - val_loss: 7.5526e-04 - val_mae: 0.0168\n",
            "Epoch 39/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0290 - val_loss: 6.8989e-04 - val_mae: 0.0160\n",
            "Epoch 40/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0289 - val_loss: 7.4978e-04 - val_mae: 0.0164\n",
            "Epoch 41/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0295 - val_loss: 5.5383e-04 - val_mae: 0.0143\n",
            "Epoch 42/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0279 - val_loss: 6.2301e-04 - val_mae: 0.0150\n",
            "Epoch 43/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0277 - val_loss: 6.2045e-04 - val_mae: 0.0148\n",
            "Epoch 44/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0091 - mae: 0.0276 - val_loss: 4.5980e-04 - val_mae: 0.0125\n",
            "Epoch 45/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0268 - val_loss: 5.2866e-04 - val_mae: 0.0136\n",
            "Epoch 46/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0268 - val_loss: 4.6734e-04 - val_mae: 0.0128\n",
            "Epoch 47/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0261 - val_loss: 6.6940e-04 - val_mae: 0.0146\n",
            "Epoch 48/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0263 - val_loss: 7.5988e-04 - val_mae: 0.0152\n",
            "Epoch 49/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0269 - val_loss: 4.7168e-04 - val_mae: 0.0126\n",
            "Epoch 50/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0259 - val_loss: 4.3846e-04 - val_mae: 0.0122\n",
            "Epoch 51/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0093 - mae: 0.0255 - val_loss: 3.6838e-04 - val_mae: 0.0109\n",
            "Epoch 52/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0251 - val_loss: 3.7362e-04 - val_mae: 0.0112\n",
            "Epoch 53/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0251 - val_loss: 3.6086e-04 - val_mae: 0.0110\n",
            "Epoch 54/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0249 - val_loss: 3.7855e-04 - val_mae: 0.0112\n",
            "Epoch 55/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0247 - val_loss: 4.0537e-04 - val_mae: 0.0114\n",
            "Epoch 56/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0250 - val_loss: 3.8396e-04 - val_mae: 0.0111\n",
            "Epoch 57/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0094 - mae: 0.0246 - val_loss: 3.5542e-04 - val_mae: 0.0107\n",
            "Epoch 58/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0243 - val_loss: 3.2924e-04 - val_mae: 0.0103\n",
            "Epoch 59/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0241 - val_loss: 3.4130e-04 - val_mae: 0.0104\n",
            "Epoch 60/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0239 - val_loss: 3.9403e-04 - val_mae: 0.0109\n",
            "Epoch 61/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0238 - val_loss: 3.9442e-04 - val_mae: 0.0109\n",
            "Epoch 62/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0241 - val_loss: 3.5747e-04 - val_mae: 0.0104\n",
            "Epoch 63/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0235 - val_loss: 3.2539e-04 - val_mae: 0.0100\n",
            "Epoch 64/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0231 - val_loss: 4.8990e-04 - val_mae: 0.0116\n",
            "Epoch 65/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0236 - val_loss: 2.9964e-04 - val_mae: 0.0096\n",
            "Epoch 66/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0230 - val_loss: 3.0681e-04 - val_mae: 0.0096\n",
            "Epoch 67/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0233 - val_loss: 3.1811e-04 - val_mae: 0.0097\n",
            "Epoch 68/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0233 - val_loss: 2.7855e-04 - val_mae: 0.0091\n",
            "Epoch 69/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0226 - val_loss: 2.9554e-04 - val_mae: 0.0093\n",
            "Epoch 70/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0227 - val_loss: 2.5041e-04 - val_mae: 0.0086\n",
            "Epoch 71/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0217 - val_loss: 2.9248e-04 - val_mae: 0.0091\n",
            "Epoch 72/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0219 - val_loss: 2.6280e-04 - val_mae: 0.0087\n",
            "Epoch 73/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0222 - val_loss: 2.2867e-04 - val_mae: 0.0082\n",
            "Epoch 74/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0219 - val_loss: 2.1062e-04 - val_mae: 0.0078\n",
            "Epoch 75/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0220 - val_loss: 2.3009e-04 - val_mae: 0.0081\n",
            "Epoch 76/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0216 - val_loss: 2.1905e-04 - val_mae: 0.0079\n",
            "Epoch 77/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0216 - val_loss: 2.3070e-04 - val_mae: 0.0081\n",
            "Epoch 78/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0213 - val_loss: 2.3693e-04 - val_mae: 0.0081\n",
            "Epoch 79/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0215 - val_loss: 1.9586e-04 - val_mae: 0.0075\n",
            "Epoch 80/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0214 - val_loss: 1.9120e-04 - val_mae: 0.0074\n",
            "Epoch 81/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0214 - val_loss: 1.8558e-04 - val_mae: 0.0072\n",
            "Epoch 82/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0211 - val_loss: 1.7808e-04 - val_mae: 0.0070\n",
            "Epoch 83/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0208 - val_loss: 3.1436e-04 - val_mae: 0.0088\n",
            "Epoch 84/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0220 - val_loss: 2.7661e-04 - val_mae: 0.0084\n",
            "Epoch 85/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0209 - val_loss: 2.0722e-04 - val_mae: 0.0075\n",
            "Epoch 86/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0203 - val_loss: 2.0307e-04 - val_mae: 0.0074\n",
            "Epoch 87/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0209 - val_loss: 1.6306e-04 - val_mae: 0.0066\n",
            "Epoch 88/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0206 - val_loss: 1.6484e-04 - val_mae: 0.0067\n",
            "Epoch 89/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0097 - mae: 0.0209 - val_loss: 1.7874e-04 - val_mae: 0.0070\n",
            "Epoch 90/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0206 - val_loss: 1.9483e-04 - val_mae: 0.0072\n",
            "Epoch 91/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0202 - val_loss: 2.9219e-04 - val_mae: 0.0084\n",
            "Epoch 92/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0215 - val_loss: 2.1418e-04 - val_mae: 0.0074\n",
            "Epoch 93/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0215 - val_loss: 1.6769e-04 - val_mae: 0.0067\n",
            "Epoch 94/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0210 - val_loss: 1.7313e-04 - val_mae: 0.0068\n",
            "Epoch 95/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0207 - val_loss: 1.6064e-04 - val_mae: 0.0066\n",
            "Epoch 96/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0202 - val_loss: 1.7886e-04 - val_mae: 0.0069\n",
            "Epoch 97/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0203 - val_loss: 1.6969e-04 - val_mae: 0.0067\n",
            "Epoch 98/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0203 - val_loss: 1.5562e-04 - val_mae: 0.0064\n",
            "Epoch 99/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0201 - val_loss: 1.4481e-04 - val_mae: 0.0061\n",
            "Epoch 100/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0203 - val_loss: 1.5569e-04 - val_mae: 0.0064\n",
            "Epoch 101/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0198 - val_loss: 1.7066e-04 - val_mae: 0.0066\n",
            "Epoch 102/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0202 - val_loss: 1.5900e-04 - val_mae: 0.0064\n",
            "Epoch 103/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0201 - val_loss: 1.7983e-04 - val_mae: 0.0067\n",
            "Epoch 104/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0200 - val_loss: 1.8630e-04 - val_mae: 0.0068\n",
            "Epoch 105/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0194 - val_loss: 3.8294e-04 - val_mae: 0.0087\n",
            "Epoch 106/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0204 - val_loss: 1.6539e-04 - val_mae: 0.0064\n",
            "Epoch 107/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0198 - val_loss: 1.4658e-04 - val_mae: 0.0061\n",
            "Epoch 108/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0195 - val_loss: 1.3652e-04 - val_mae: 0.0059\n",
            "Epoch 109/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0196 - val_loss: 1.5539e-04 - val_mae: 0.0062\n",
            "Epoch 110/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0198 - val_loss: 1.5483e-04 - val_mae: 0.0062\n",
            "Epoch 111/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0195 - val_loss: 1.2410e-04 - val_mae: 0.0056\n",
            "Epoch 112/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0195 - val_loss: 1.3009e-04 - val_mae: 0.0057\n",
            "Epoch 113/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0192 - val_loss: 1.2637e-04 - val_mae: 0.0057\n",
            "Epoch 114/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0198 - val_loss: 1.1769e-04 - val_mae: 0.0054\n",
            "Epoch 115/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0192 - val_loss: 1.9108e-04 - val_mae: 0.0065\n",
            "Epoch 116/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0197 - val_loss: 1.3273e-04 - val_mae: 0.0057\n",
            "Epoch 117/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0201 - val_loss: 1.3904e-04 - val_mae: 0.0058\n",
            "Epoch 118/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0192 - val_loss: 1.3352e-04 - val_mae: 0.0057\n",
            "Epoch 119/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0095 - mae: 0.0191 - val_loss: 1.2057e-04 - val_mae: 0.0051\n",
            "Epoch 120/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0189 - val_loss: 1.1800e-04 - val_mae: 0.0054\n",
            "Epoch 121/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0191 - val_loss: 1.1376e-04 - val_mae: 0.0053\n",
            "Epoch 122/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0189 - val_loss: 1.1816e-04 - val_mae: 0.0054\n",
            "Epoch 123/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0194 - val_loss: 1.2516e-04 - val_mae: 0.0055\n",
            "Epoch 124/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0190 - val_loss: 1.2041e-04 - val_mae: 0.0054\n",
            "Epoch 125/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0188 - val_loss: 1.2877e-04 - val_mae: 0.0055\n",
            "Epoch 126/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0190 - val_loss: 1.0333e-04 - val_mae: 0.0050\n",
            "Epoch 127/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0190 - val_loss: 1.1890e-04 - val_mae: 0.0054\n",
            "Epoch 128/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0189 - val_loss: 1.1886e-04 - val_mae: 0.0053\n",
            "Epoch 129/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0189 - val_loss: 1.1245e-04 - val_mae: 0.0052\n",
            "Epoch 130/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0189 - val_loss: 9.9568e-05 - val_mae: 0.0048\n",
            "Epoch 131/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0188 - val_loss: 1.0491e-04 - val_mae: 0.0050\n",
            "Epoch 132/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0185 - val_loss: 1.1218e-04 - val_mae: 0.0052\n",
            "Epoch 133/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0186 - val_loss: 1.1708e-04 - val_mae: 0.0053\n",
            "Epoch 134/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0189 - val_loss: 1.1989e-04 - val_mae: 0.0053\n",
            "Epoch 135/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0182 - val_loss: 1.3724e-04 - val_mae: 0.0055\n",
            "Epoch 136/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0185 - val_loss: 1.3228e-04 - val_mae: 0.0055\n",
            "Epoch 137/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0187 - val_loss: 1.0449e-04 - val_mae: 0.0050\n",
            "Epoch 138/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0184 - val_loss: 9.8869e-05 - val_mae: 0.0049\n",
            "Epoch 139/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0183 - val_loss: 1.1258e-04 - val_mae: 0.0051\n",
            "Epoch 140/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0181 - val_loss: 1.7763e-04 - val_mae: 0.0060\n",
            "Epoch 141/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0194 - val_loss: 1.0772e-04 - val_mae: 0.0050\n",
            "Epoch 142/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0184 - val_loss: 1.0972e-04 - val_mae: 0.0050\n",
            "Epoch 143/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0197 - val_loss: 1.6398e-04 - val_mae: 0.0057\n",
            "Epoch 144/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0186 - val_loss: 1.3849e-04 - val_mae: 0.0054\n",
            "Epoch 145/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0179 - val_loss: 9.5145e-05 - val_mae: 0.0047\n",
            "Epoch 146/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0186 - val_loss: 1.0275e-04 - val_mae: 0.0048\n",
            "Epoch 147/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0184 - val_loss: 8.2653e-05 - val_mae: 0.0044\n",
            "Epoch 148/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0186 - val_loss: 8.4193e-05 - val_mae: 0.0044\n",
            "Epoch 149/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0182 - val_loss: 9.7663e-05 - val_mae: 0.0047\n",
            "Epoch 150/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0182 - val_loss: 9.5767e-05 - val_mae: 0.0047\n",
            "Epoch 151/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0180 - val_loss: 9.8908e-05 - val_mae: 0.0047\n",
            "Epoch 152/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0184 - val_loss: 9.3257e-05 - val_mae: 0.0046\n",
            "Epoch 153/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0187 - val_loss: 1.0070e-04 - val_mae: 0.0047\n",
            "Epoch 154/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0185 - val_loss: 8.8516e-05 - val_mae: 0.0045\n",
            "Epoch 155/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0187 - val_loss: 1.2716e-04 - val_mae: 0.0051\n",
            "Epoch 156/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0182 - val_loss: 1.0868e-04 - val_mae: 0.0049\n",
            "Epoch 157/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0178 - val_loss: 8.4390e-05 - val_mae: 0.0044\n",
            "Epoch 158/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0179 - val_loss: 8.1743e-05 - val_mae: 0.0043\n",
            "Epoch 159/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0180 - val_loss: 7.7352e-05 - val_mae: 0.0042\n",
            "Epoch 160/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0182 - val_loss: 1.0913e-04 - val_mae: 0.0048\n",
            "Epoch 161/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0179 - val_loss: 8.1721e-05 - val_mae: 0.0043\n",
            "Epoch 162/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0175 - val_loss: 8.7261e-05 - val_mae: 0.0044\n",
            "Epoch 163/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0178 - val_loss: 1.0085e-04 - val_mae: 0.0046\n",
            "Epoch 164/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0178 - val_loss: 7.7055e-05 - val_mae: 0.0042\n",
            "Epoch 165/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0177 - val_loss: 8.1592e-05 - val_mae: 0.0043\n",
            "Epoch 166/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0181 - val_loss: 7.5534e-05 - val_mae: 0.0041\n",
            "Epoch 167/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0175 - val_loss: 7.9831e-05 - val_mae: 0.0042\n",
            "Epoch 168/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0180 - val_loss: 1.1125e-04 - val_mae: 0.0047\n",
            "Epoch 169/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0183 - val_loss: 7.9133e-05 - val_mae: 0.0042\n",
            "Epoch 170/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0176 - val_loss: 7.3538e-05 - val_mae: 0.0041\n",
            "Epoch 171/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0176 - val_loss: 6.9265e-05 - val_mae: 0.0039\n",
            "Epoch 172/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0174 - val_loss: 7.4386e-05 - val_mae: 0.0041\n",
            "Epoch 173/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0175 - val_loss: 6.6983e-05 - val_mae: 0.0038\n",
            "Epoch 174/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0173 - val_loss: 6.9352e-05 - val_mae: 0.0039\n",
            "Epoch 175/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0178 - val_loss: 6.8028e-05 - val_mae: 0.0039\n",
            "Epoch 176/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0175 - val_loss: 6.5666e-05 - val_mae: 0.0038\n",
            "Epoch 177/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0176 - val_loss: 6.5240e-05 - val_mae: 0.0038\n",
            "Epoch 178/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0171 - val_loss: 7.8067e-05 - val_mae: 0.0037\n",
            "Epoch 179/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0175 - val_loss: 6.5597e-05 - val_mae: 0.0037\n",
            "Epoch 180/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0174 - val_loss: 7.1079e-05 - val_mae: 0.0039\n",
            "Epoch 181/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0174 - val_loss: 7.5270e-05 - val_mae: 0.0040\n",
            "Epoch 182/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0179 - val_loss: 6.9648e-05 - val_mae: 0.0039\n",
            "Epoch 183/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0174 - val_loss: 8.3410e-05 - val_mae: 0.0042\n",
            "Epoch 184/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0177 - val_loss: 6.1202e-05 - val_mae: 0.0036\n",
            "Epoch 185/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0174 - val_loss: 6.3330e-05 - val_mae: 0.0037\n",
            "Epoch 186/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0176 - val_loss: 6.0084e-05 - val_mae: 0.0036\n",
            "Epoch 187/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0172 - val_loss: 5.9599e-05 - val_mae: 0.0036\n",
            "Epoch 188/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0177 - val_loss: 6.9745e-05 - val_mae: 0.0039\n",
            "Epoch 189/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0172 - val_loss: 6.1375e-05 - val_mae: 0.0037\n",
            "Epoch 190/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0171 - val_loss: 6.2262e-05 - val_mae: 0.0037\n",
            "Epoch 191/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0173 - val_loss: 6.2822e-05 - val_mae: 0.0037\n",
            "Epoch 192/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0173 - val_loss: 5.8072e-05 - val_mae: 0.0035\n",
            "Epoch 193/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0175 - val_loss: 5.7496e-05 - val_mae: 0.0035\n",
            "Epoch 194/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0169 - val_loss: 6.1775e-05 - val_mae: 0.0037\n",
            "Epoch 195/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0173 - val_loss: 6.3994e-05 - val_mae: 0.0037\n",
            "Epoch 196/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0174 - val_loss: 6.5752e-05 - val_mae: 0.0037\n",
            "Epoch 197/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0173 - val_loss: 7.1194e-05 - val_mae: 0.0038\n",
            "Epoch 198/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0177 - val_loss: 7.2927e-05 - val_mae: 0.0039\n",
            "Epoch 199/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0173 - val_loss: 5.6475e-05 - val_mae: 0.0034\n",
            "Epoch 200/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0173 - val_loss: 7.6348e-05 - val_mae: 0.0039\n",
            "Epoch 201/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0176 - val_loss: 5.9809e-05 - val_mae: 0.0036\n",
            "Epoch 202/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0167 - val_loss: 5.6771e-05 - val_mae: 0.0035\n",
            "Epoch 203/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0170 - val_loss: 5.5889e-05 - val_mae: 0.0035\n",
            "Epoch 204/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0174 - val_loss: 5.6222e-05 - val_mae: 0.0035\n",
            "Epoch 205/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0171 - val_loss: 5.5725e-05 - val_mae: 0.0034\n",
            "Epoch 206/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0175 - val_loss: 6.3705e-05 - val_mae: 0.0036\n",
            "Epoch 207/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0171 - val_loss: 5.7593e-05 - val_mae: 0.0035\n",
            "Epoch 208/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0166 - val_loss: 5.3956e-05 - val_mae: 0.0033\n",
            "Epoch 209/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0171 - val_loss: 5.3388e-05 - val_mae: 0.0033\n",
            "Epoch 210/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0171 - val_loss: 6.2001e-05 - val_mae: 0.0032\n",
            "Epoch 211/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0170 - val_loss: 6.1464e-05 - val_mae: 0.0032\n",
            "Epoch 212/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0172 - val_loss: 5.2084e-05 - val_mae: 0.0032\n",
            "Epoch 213/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0170 - val_loss: 5.3574e-05 - val_mae: 0.0034\n",
            "Epoch 214/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0168 - val_loss: 8.8498e-05 - val_mae: 0.0040\n",
            "Epoch 215/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0171 - val_loss: 6.8987e-05 - val_mae: 0.0037\n",
            "Epoch 216/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0172 - val_loss: 5.8186e-05 - val_mae: 0.0035\n",
            "Epoch 217/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0170 - val_loss: 5.6618e-05 - val_mae: 0.0034\n",
            "Epoch 218/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0166 - val_loss: 6.0020e-05 - val_mae: 0.0035\n",
            "Epoch 219/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0170 - val_loss: 5.0128e-05 - val_mae: 0.0032\n",
            "Epoch 220/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0169 - val_loss: 4.9754e-05 - val_mae: 0.0032\n",
            "Epoch 221/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0169 - val_loss: 5.1117e-05 - val_mae: 0.0033\n",
            "Epoch 222/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0167 - val_loss: 5.7437e-05 - val_mae: 0.0034\n",
            "Epoch 223/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0168 - val_loss: 5.1334e-05 - val_mae: 0.0033\n",
            "Epoch 224/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0167 - val_loss: 5.2073e-05 - val_mae: 0.0033\n",
            "Epoch 225/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0171 - val_loss: 5.4702e-05 - val_mae: 0.0034\n",
            "Epoch 226/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0167 - val_loss: 4.8359e-05 - val_mae: 0.0031\n",
            "Epoch 227/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0098 - mae: 0.0168 - val_loss: 6.3803e-05 - val_mae: 0.0035\n",
            "Epoch 228/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0171 - val_loss: 6.0091e-05 - val_mae: 0.0035\n",
            "Epoch 229/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0169 - val_loss: 7.0474e-05 - val_mae: 0.0037\n",
            "Epoch 230/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0170 - val_loss: 7.6613e-05 - val_mae: 0.0038\n",
            "Epoch 231/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0172 - val_loss: 6.3717e-05 - val_mae: 0.0035\n",
            "Epoch 232/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0168 - val_loss: 5.6732e-05 - val_mae: 0.0034\n",
            "Epoch 233/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0173 - val_loss: 6.8649e-05 - val_mae: 0.0036\n",
            "Epoch 234/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0171 - val_loss: 7.2028e-05 - val_mae: 0.0037\n",
            "Epoch 235/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0171 - val_loss: 4.9848e-05 - val_mae: 0.0032\n",
            "Epoch 236/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0166 - val_loss: 5.2869e-05 - val_mae: 0.0030\n",
            "Epoch 237/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0168 - val_loss: 5.2208e-05 - val_mae: 0.0033\n",
            "Epoch 238/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0167 - val_loss: 4.6756e-05 - val_mae: 0.0031\n",
            "Epoch 239/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0168 - val_loss: 4.9179e-05 - val_mae: 0.0032\n",
            "Epoch 240/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0170 - val_loss: 4.5077e-05 - val_mae: 0.0030\n",
            "Epoch 241/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0165 - val_loss: 4.4576e-05 - val_mae: 0.0030\n",
            "Epoch 242/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0164 - val_loss: 4.6335e-05 - val_mae: 0.0030\n",
            "Epoch 243/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0170 - val_loss: 4.4739e-05 - val_mae: 0.0030\n",
            "Epoch 244/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0167 - val_loss: 4.4769e-05 - val_mae: 0.0030\n",
            "Epoch 245/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0173 - val_loss: 4.4363e-05 - val_mae: 0.0030\n",
            "Epoch 246/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0163 - val_loss: 4.4476e-05 - val_mae: 0.0030\n",
            "Epoch 247/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0166 - val_loss: 4.6655e-05 - val_mae: 0.0031\n",
            "Epoch 248/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0167 - val_loss: 4.3387e-05 - val_mae: 0.0030\n",
            "Epoch 249/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0167 - val_loss: 4.5540e-05 - val_mae: 0.0030\n",
            "Epoch 250/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0172 - val_loss: 5.0911e-05 - val_mae: 0.0032\n",
            "Epoch 251/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0167 - val_loss: 6.4794e-05 - val_mae: 0.0035\n",
            "Epoch 252/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0169 - val_loss: 4.9854e-05 - val_mae: 0.0032\n",
            "Epoch 253/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0168 - val_loss: 4.5075e-05 - val_mae: 0.0030\n",
            "Epoch 254/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0166 - val_loss: 4.3032e-05 - val_mae: 0.0029\n",
            "Epoch 255/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0164 - val_loss: 4.4054e-05 - val_mae: 0.0029\n",
            "Epoch 256/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0166 - val_loss: 4.2828e-05 - val_mae: 0.0029\n",
            "Epoch 257/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0163 - val_loss: 4.6592e-05 - val_mae: 0.0031\n",
            "Epoch 258/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0176 - val_loss: 4.9481e-05 - val_mae: 0.0031\n",
            "Epoch 259/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0164 - val_loss: 4.1984e-05 - val_mae: 0.0029\n",
            "Epoch 260/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0166 - val_loss: 4.2450e-05 - val_mae: 0.0029\n",
            "Epoch 261/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0167 - val_loss: 4.9130e-05 - val_mae: 0.0028\n",
            "Epoch 262/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0168 - val_loss: 4.5078e-05 - val_mae: 0.0030\n",
            "Epoch 263/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0164 - val_loss: 4.9777e-05 - val_mae: 0.0031\n",
            "Epoch 264/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0165 - val_loss: 5.5443e-05 - val_mae: 0.0032\n",
            "Epoch 265/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0167 - val_loss: 4.7670e-05 - val_mae: 0.0031\n",
            "Epoch 266/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0165 - val_loss: 4.1555e-05 - val_mae: 0.0029\n",
            "Epoch 267/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0164 - val_loss: 6.6020e-05 - val_mae: 0.0034\n",
            "Epoch 268/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0166 - val_loss: 7.0393e-05 - val_mae: 0.0035\n",
            "Epoch 269/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0169 - val_loss: 6.8152e-05 - val_mae: 0.0035\n",
            "Epoch 270/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0168 - val_loss: 6.5220e-05 - val_mae: 0.0034\n",
            "Epoch 271/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0168 - val_loss: 4.3974e-05 - val_mae: 0.0030\n",
            "Epoch 272/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0161 - val_loss: 4.0858e-05 - val_mae: 0.0028\n",
            "Epoch 273/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0167 - val_loss: 4.1232e-05 - val_mae: 0.0028\n",
            "Epoch 274/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0164 - val_loss: 4.1565e-05 - val_mae: 0.0028\n",
            "Epoch 275/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0169 - val_loss: 5.7862e-05 - val_mae: 0.0033\n",
            "Epoch 276/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0164 - val_loss: 5.8623e-05 - val_mae: 0.0033\n",
            "Epoch 277/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0167 - val_loss: 4.9181e-05 - val_mae: 0.0031\n",
            "Epoch 278/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0167 - val_loss: 4.7483e-05 - val_mae: 0.0031\n",
            "Epoch 279/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0168 - val_loss: 5.8760e-05 - val_mae: 0.0033\n",
            "Epoch 280/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0172 - val_loss: 4.4815e-05 - val_mae: 0.0030\n",
            "Epoch 281/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0169 - val_loss: 4.1337e-05 - val_mae: 0.0029\n",
            "Epoch 282/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0166 - val_loss: 4.1772e-05 - val_mae: 0.0029\n",
            "Epoch 283/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0166 - val_loss: 4.4873e-05 - val_mae: 0.0030\n",
            "Epoch 284/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0164 - val_loss: 4.3360e-05 - val_mae: 0.0029\n",
            "Epoch 285/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0173 - val_loss: 5.6531e-05 - val_mae: 0.0032\n",
            "Epoch 286/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0166 - val_loss: 4.0294e-05 - val_mae: 0.0028\n",
            "Epoch 287/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0169 - val_loss: 4.7740e-05 - val_mae: 0.0031\n",
            "Epoch 288/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0162 - val_loss: 4.9775e-05 - val_mae: 0.0031\n",
            "Epoch 289/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0166 - val_loss: 4.4444e-05 - val_mae: 0.0030\n",
            "Epoch 290/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0166 - val_loss: 4.0830e-05 - val_mae: 0.0027\n",
            "Epoch 291/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0164 - val_loss: 3.9523e-05 - val_mae: 0.0028\n",
            "Epoch 292/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0164 - val_loss: 4.0968e-05 - val_mae: 0.0027\n",
            "Epoch 293/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0167 - val_loss: 3.9568e-05 - val_mae: 0.0028\n",
            "Epoch 294/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0162 - val_loss: 3.9174e-05 - val_mae: 0.0028\n",
            "Epoch 295/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0167 - val_loss: 4.9842e-05 - val_mae: 0.0031\n",
            "Epoch 296/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0164 - val_loss: 5.5149e-05 - val_mae: 0.0032\n",
            "Epoch 297/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0096 - mae: 0.0166 - val_loss: 4.1979e-05 - val_mae: 0.0027\n",
            "Epoch 298/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0169 - val_loss: 4.7769e-05 - val_mae: 0.0027\n",
            "Epoch 299/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0161 - val_loss: 3.8733e-05 - val_mae: 0.0028\n",
            "Epoch 300/400\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0166 - val_loss: 4.6172e-05 - val_mae: 0.0030\n",
            "Epoch 301/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0165 - val_loss: 4.0616e-05 - val_mae: 0.0028\n",
            "Epoch 302/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0169 - val_loss: 3.8850e-05 - val_mae: 0.0028\n",
            "Epoch 303/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0168 - val_loss: 4.0510e-05 - val_mae: 0.0028\n",
            "Epoch 304/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0167 - val_loss: 3.9073e-05 - val_mae: 0.0028\n",
            "Epoch 305/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0165 - val_loss: 4.5159e-05 - val_mae: 0.0030\n",
            "Epoch 306/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0164 - val_loss: 4.5960e-05 - val_mae: 0.0030\n",
            "Epoch 307/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0169 - val_loss: 5.2140e-05 - val_mae: 0.0031\n",
            "Epoch 308/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0164 - val_loss: 3.8484e-05 - val_mae: 0.0027\n",
            "Epoch 309/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0161 - val_loss: 3.7988e-05 - val_mae: 0.0027\n",
            "Epoch 310/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0163 - val_loss: 4.0209e-05 - val_mae: 0.0028\n",
            "Epoch 311/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0160 - val_loss: 4.5361e-05 - val_mae: 0.0029\n",
            "Epoch 312/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0161 - val_loss: 3.8687e-05 - val_mae: 0.0028\n",
            "Epoch 313/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0162 - val_loss: 4.8660e-05 - val_mae: 0.0030\n",
            "Epoch 314/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0163 - val_loss: 3.6711e-05 - val_mae: 0.0027\n",
            "Epoch 315/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0162 - val_loss: 3.8079e-05 - val_mae: 0.0027\n",
            "Epoch 316/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0162 - val_loss: 3.9612e-05 - val_mae: 0.0028\n",
            "Epoch 317/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0160 - val_loss: 3.6315e-05 - val_mae: 0.0026\n",
            "Epoch 318/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0161 - val_loss: 3.5824e-05 - val_mae: 0.0025\n",
            "Epoch 319/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0169 - val_loss: 3.5360e-05 - val_mae: 0.0026\n",
            "Epoch 320/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0163 - val_loss: 3.8560e-05 - val_mae: 0.0027\n",
            "Epoch 321/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0162 - val_loss: 3.6142e-05 - val_mae: 0.0027\n",
            "Epoch 322/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0163 - val_loss: 3.4419e-05 - val_mae: 0.0026\n",
            "Epoch 323/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0161 - val_loss: 3.4856e-05 - val_mae: 0.0026\n",
            "Epoch 324/400\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0165 - val_loss: 3.6278e-05 - val_mae: 0.0027\n",
            "Epoch 325/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0163 - val_loss: 3.5883e-05 - val_mae: 0.0026\n",
            "Epoch 326/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0163 - val_loss: 4.6244e-05 - val_mae: 0.0029\n",
            "Epoch 327/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0107 - mae: 0.0167 - val_loss: 4.6427e-05 - val_mae: 0.0029\n",
            "Epoch 328/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0161 - val_loss: 3.3820e-05 - val_mae: 0.0026\n",
            "Epoch 329/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0161 - val_loss: 3.3750e-05 - val_mae: 0.0025\n",
            "Epoch 330/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0160 - val_loss: 3.3753e-05 - val_mae: 0.0025\n",
            "Epoch 331/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0161 - val_loss: 3.3724e-05 - val_mae: 0.0025\n",
            "Epoch 332/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0159 - val_loss: 3.3751e-05 - val_mae: 0.0025\n",
            "Epoch 333/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0163 - val_loss: 3.3519e-05 - val_mae: 0.0025\n",
            "Epoch 334/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0163 - val_loss: 3.3640e-05 - val_mae: 0.0025\n",
            "Epoch 335/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0160 - val_loss: 3.9247e-05 - val_mae: 0.0027\n",
            "Epoch 336/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0161 - val_loss: 3.6562e-05 - val_mae: 0.0026\n",
            "Epoch 337/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0161 - val_loss: 3.4931e-05 - val_mae: 0.0026\n",
            "Epoch 338/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0159 - val_loss: 3.3018e-05 - val_mae: 0.0025\n",
            "Epoch 339/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0161 - val_loss: 3.3135e-05 - val_mae: 0.0025\n",
            "Epoch 340/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0160 - val_loss: 3.2116e-05 - val_mae: 0.0025\n",
            "Epoch 341/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0161 - val_loss: 3.3340e-05 - val_mae: 0.0025\n",
            "Epoch 342/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0160 - val_loss: 3.1928e-05 - val_mae: 0.0025\n",
            "Epoch 343/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0163 - val_loss: 3.7724e-05 - val_mae: 0.0026\n",
            "Epoch 344/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0164 - val_loss: 5.2877e-05 - val_mae: 0.0030\n",
            "Epoch 345/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0163 - val_loss: 4.4087e-05 - val_mae: 0.0028\n",
            "Epoch 346/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0161 - val_loss: 4.1958e-05 - val_mae: 0.0027\n",
            "Epoch 347/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0167 - val_loss: 3.7403e-05 - val_mae: 0.0026\n",
            "Epoch 348/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0159 - val_loss: 4.0918e-05 - val_mae: 0.0027\n",
            "Epoch 349/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0163 - val_loss: 3.1462e-05 - val_mae: 0.0024\n",
            "Epoch 350/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0160 - val_loss: 3.1798e-05 - val_mae: 0.0025\n",
            "Epoch 351/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0159 - val_loss: 3.1763e-05 - val_mae: 0.0024\n",
            "Epoch 352/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0161 - val_loss: 3.3538e-05 - val_mae: 0.0025\n",
            "Epoch 353/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0160 - val_loss: 4.4603e-05 - val_mae: 0.0028\n",
            "Epoch 354/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0160 - val_loss: 3.1571e-05 - val_mae: 0.0024\n",
            "Epoch 355/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0159 - val_loss: 3.4320e-05 - val_mae: 0.0026\n",
            "Epoch 356/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0158 - val_loss: 3.1868e-05 - val_mae: 0.0024\n",
            "Epoch 357/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0158 - val_loss: 3.2154e-05 - val_mae: 0.0024\n",
            "Epoch 358/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0161 - val_loss: 3.1385e-05 - val_mae: 0.0024\n",
            "Epoch 359/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0106 - mae: 0.0167 - val_loss: 3.4956e-05 - val_mae: 0.0026\n",
            "Epoch 360/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0156 - val_loss: 3.1485e-05 - val_mae: 0.0024\n",
            "Epoch 361/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0156 - val_loss: 3.2401e-05 - val_mae: 0.0024\n",
            "Epoch 362/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0160 - val_loss: 3.2161e-05 - val_mae: 0.0025\n",
            "Epoch 363/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0160 - val_loss: 3.2545e-05 - val_mae: 0.0025\n",
            "Epoch 364/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0159 - val_loss: 3.6351e-05 - val_mae: 0.0024\n",
            "Epoch 365/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0161 - val_loss: 3.2232e-05 - val_mae: 0.0024\n",
            "Epoch 366/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0162 - val_loss: 3.1975e-05 - val_mae: 0.0025\n",
            "Epoch 367/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0159 - val_loss: 3.1140e-05 - val_mae: 0.0024\n",
            "Epoch 368/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0160 - val_loss: 3.1262e-05 - val_mae: 0.0024\n",
            "Epoch 369/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0161 - val_loss: 3.2838e-05 - val_mae: 0.0025\n",
            "Epoch 370/400\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0104 - mae: 0.0161 - val_loss: 3.0682e-05 - val_mae: 0.0024\n",
            "Epoch 371/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0158 - val_loss: 3.3653e-05 - val_mae: 0.0024\n",
            "Epoch 372/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0156 - val_loss: 3.1550e-05 - val_mae: 0.0024\n",
            "Epoch 373/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0153 - val_loss: 4.1110e-05 - val_mae: 0.0027\n",
            "Epoch 374/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0160 - val_loss: 3.4205e-05 - val_mae: 0.0025\n",
            "Epoch 375/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0159 - val_loss: 3.1846e-05 - val_mae: 0.0023\n",
            "Epoch 376/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0162 - val_loss: 3.1228e-05 - val_mae: 0.0024\n",
            "Epoch 377/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0099 - mae: 0.0159 - val_loss: 3.5786e-05 - val_mae: 0.0023\n",
            "Epoch 378/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0160 - val_loss: 3.2215e-05 - val_mae: 0.0023\n",
            "Epoch 379/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0100 - mae: 0.0160 - val_loss: 3.3448e-05 - val_mae: 0.0025\n",
            "Epoch 380/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0158 - val_loss: 3.6738e-05 - val_mae: 0.0026\n",
            "Epoch 381/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0158 - val_loss: 3.1203e-05 - val_mae: 0.0024\n",
            "Epoch 382/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0157 - val_loss: 3.3222e-05 - val_mae: 0.0023\n",
            "Epoch 383/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0166 - val_loss: 3.3203e-05 - val_mae: 0.0023\n",
            "Epoch 384/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0161 - val_loss: 2.9284e-05 - val_mae: 0.0023\n",
            "Epoch 385/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0159 - val_loss: 2.9402e-05 - val_mae: 0.0023\n",
            "Epoch 386/400\n",
            "70/70 [==============================] - 0s 3ms/step - loss: 0.0105 - mae: 0.0161 - val_loss: 3.3307e-05 - val_mae: 0.0025\n",
            "Epoch 387/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0158 - val_loss: 3.0429e-05 - val_mae: 0.0024\n",
            "Epoch 388/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0157 - val_loss: 3.3814e-05 - val_mae: 0.0025\n",
            "Epoch 389/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0161 - val_loss: 3.7888e-05 - val_mae: 0.0026\n",
            "Epoch 390/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0163 - val_loss: 3.1265e-05 - val_mae: 0.0024\n",
            "Epoch 391/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0159 - val_loss: 3.1881e-05 - val_mae: 0.0024\n",
            "Epoch 392/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0158 - val_loss: 3.9470e-05 - val_mae: 0.0026\n",
            "Epoch 393/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0165 - val_loss: 3.0835e-05 - val_mae: 0.0024\n",
            "Epoch 394/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0158 - val_loss: 3.7061e-05 - val_mae: 0.0026\n",
            "Epoch 395/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0160 - val_loss: 3.1689e-05 - val_mae: 0.0024\n",
            "Epoch 396/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0102 - mae: 0.0158 - val_loss: 2.9147e-05 - val_mae: 0.0023\n",
            "Epoch 397/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0104 - mae: 0.0161 - val_loss: 2.9045e-05 - val_mae: 0.0023\n",
            "Epoch 398/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0101 - mae: 0.0155 - val_loss: 3.0980e-05 - val_mae: 0.0024\n",
            "Epoch 399/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0103 - mae: 0.0161 - val_loss: 3.0008e-05 - val_mae: 0.0023\n",
            "Epoch 400/400\n",
            "70/70 [==============================] - 0s 2ms/step - loss: 0.0105 - mae: 0.0168 - val_loss: 3.1645e-05 - val_mae: 0.0024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bd40a4b-0756-4e65-9ab6-ef259679515a"
      },
      "source": [
        "# use the model to predict the test inputs\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# print the predictions and the expected ouputs\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "plt.plot(inputs_test, outputs_test, 'b.', label='Actual')\n",
        "plt.plot(inputs_test, predictions, 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions =\n",
            " [[0.998 0.002]\n",
            " [0.001 0.999]\n",
            " [0.999 0.001]\n",
            " [0.087 0.913]\n",
            " [0.997 0.003]\n",
            " [0.164 0.836]\n",
            " [0.994 0.006]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.012 0.988]\n",
            " [0.997 0.003]\n",
            " [0.001 0.999]\n",
            " [0.995 0.005]\n",
            " [0.999 0.001]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]\n",
            " [0.997 0.003]\n",
            " [0.    1.   ]\n",
            " [0.002 0.998]\n",
            " [0.997 0.003]\n",
            " [0.    1.   ]\n",
            " [0.998 0.002]\n",
            " [0.001 0.999]\n",
            " [0.    1.   ]\n",
            " [0.996 0.004]\n",
            " [0.    1.   ]\n",
            " [0.998 0.002]\n",
            " [0.001 0.999]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.015 0.985]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.998 0.002]\n",
            " [0.998 0.002]\n",
            " [0.997 0.003]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]\n",
            " [0.998 0.002]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]\n",
            " [0.006 0.994]\n",
            " [0.998 0.002]\n",
            " [0.987 0.013]\n",
            " [0.001 0.999]\n",
            " [0.    1.   ]\n",
            " [0.003 0.997]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]\n",
            " [0.998 0.002]\n",
            " [0.    1.   ]\n",
            " [0.001 0.999]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.001 0.999]\n",
            " [0.002 0.998]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.003 0.997]\n",
            " [0.997 0.003]\n",
            " [0.995 0.005]\n",
            " [0.997 0.003]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]\n",
            " [0.997 0.003]\n",
            " [0.002 0.998]\n",
            " [0.001 0.999]\n",
            " [0.    1.   ]\n",
            " [0.    1.   ]\n",
            " [0.999 0.001]\n",
            " [0.    1.   ]\n",
            " [0.997 0.003]]\n",
            "actual =\n",
            " [[1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: MatplotlibDeprecationWarning: cycling among columns of inputs with non-matching shapes is deprecated.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: MatplotlibDeprecationWarning: cycling among columns of inputs with non-matching shapes is deprecated.\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3fb3c7f-0636-454f-ba5f-4734d16622fd"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "  \n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Model is %d bytes\" % basic_model_size)\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcsmhvzfs/assets\n",
            "Model is 2132 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc52bd4-fe0a-455f-f29c-5e0707e29e6b"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Header file, model.h, is {model_h_size:,} bytes.\")\n",
        "print(\"\\nOpen the side panel (refresh if needed). Double click model.h to download the file.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Header file, model.h, is 13,182 bytes.\n",
            "\n",
            "Open the side panel (refresh if needed). Double click model.h to download the file.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}